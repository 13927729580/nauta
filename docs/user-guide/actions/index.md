# Product Overview

The IntelÂ® Deep Learning Studio software provides a multi-user, distributed computing environment for running deep learning model training experiments.  Results of experiments, can be viewed and monitored using a command line interface, web UI and/or TensorBoard*. You can use existing data sets, use your own data, or downloaded data from online sources, and create public or private folders to make collaboration amongst teams easier. Intel DL Studio runs using the industry leading Kubernetes* and Docker* platform for scalability and ease of management. Templates are available (and customizable) on the platform to take the complexities out of creating and running single and multi-node deep learning training experiments without all the systems overhead and scripting needed with standard container environments.  To test your model, Intel DL Studio also supports both batch and streaming inference, all in a single platform.

The Intel DL Studio client software runs on the following operating systems:

* Ubuntu* 16.04
* macOS*
* Windows* 10
 
# Purpose of this Guide

This guide describes how to use the Intel DL Studio and discusses the following topics:

* [Basic Concepts](concepts.md)
* [Client Installation and Configuration](install_configure.md)
* [Getting Started](getting_started.md)
* [Working with Datasets](working_with_datasets.md)
* [Working with Experiments](working_with_experiments.md)
* [Working with Template Packs](template_packs.md)
* [Evaluating Experiments](view_exp.md)
* [Evaluating Experiments with Inference Testing](inference_testing.md)
* [Managing Users and Resources](managing_users_resources.md)
* [CLI Commands](view_cli_help.md)
 
